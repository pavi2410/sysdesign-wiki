---
name: YouTube
tagline: The world's largest video platform serving billions of hours daily
category: streaming
tags: [streaming, video, CDN, recommendation, transcoding, ads]
---
import { Mermaid, Scale, ComponentList, ComponentCard, Requirements, Tradeoff } from '@/components/mdx';

## Overview

YouTube is the world's largest video sharing platform, with 2.7B+ monthly active users watching over 1 billion hours of video every day. Its architecture must handle massive-scale video ingestion (500+ hours uploaded per minute), transcoding into dozens of formats and resolutions, a globally distributed CDN for low-latency playback, a recommendation engine that drives 70% of watch time, and a real-time ad serving system. YouTube's infrastructure runs on Google's global network and leverages custom hardware for video transcoding at scale.

## Scale

<Scale items={{
  "Monthly active users": "2.7B+",
  "Hours of video watched/day": "1B+",
  "Video uploads per minute": "500+ hours",
  "Content library": "800M+ videos",
}} />

## Requirements

<Requirements
  functional={[
    'Video upload, transcoding, and playback',
    'Adaptive bitrate streaming (DASH/HLS)',
    'Personalized recommendation feed',
    'Live streaming with real-time chat',
    'Comments, likes, subscriptions, and notifications',
    'Monetization: ads, memberships, Super Chat',
    'Content moderation and copyright detection (Content ID)',
  ]}
  nonFunctional={[
    'Playback start time \<2 seconds globally',
    'Zero buffering for 95%+ of playback sessions',
    'Transcoding throughput for 500+ hours/minute of uploads',
    'Recommendation latency \<200ms per request',
    'Ad serving latency \<100ms',
    'Global CDN with 99.99% availability',
  ]}
/>

## High-Level Architecture

<Mermaid chart={`graph TB
    subgraph Clients
        WEB[Web Player]
        MOB[Mobile App]
        TV[Smart TV / Cast]
        CREATOR[Creator Studio]
    end
    subgraph Edge["Edge / CDN"]
        GCDN[Google CDN Edge PoPs]
        LB[Load Balancer]
    end
    subgraph Services["Core Services"]
        UPLOAD[Upload Service]
        TRANSCODE[Transcoding Pipeline]
        PLAY[Playback Service]
        REC[Recommendation Engine]
        ADS[Ad Serving]
        SEARCH[Search Service]
        LIVE[Live Service]
        MODERATE[Content Moderation]
    end
    subgraph Storage["Storage"]
        BLOB[(Video Blob Store)]
        META[(Video Metadata DB)]
        GRAPH[(Social Graph)]
        ADDB[(Ad Inventory)]
        MLMODEL[(ML Models)]
    end
    WEB & MOB & TV --> GCDN
    CREATOR --> LB
    GCDN --> PLAY
    LB --> UPLOAD & SEARCH & REC
    UPLOAD --> TRANSCODE
    TRANSCODE --> BLOB
    PLAY --> BLOB & META
    REC --> META & GRAPH & MLMODEL
    ADS --> ADDB
    MODERATE --> MLMODEL
    LIVE --> GCDN`} caption="YouTube — High-level system architecture" />

## Key Components

<ComponentList>
<ComponentCard name="Upload & Ingestion Service">
Handles video uploads with resumable upload support. Validates file formats, extracts metadata, generates initial thumbnails, and queues the video for transcoding. Supports uploads up to 256GB per video.
</ComponentCard>
<ComponentCard name="Transcoding Pipeline">
Converts uploaded videos into 10+ resolution/codec combinations (144p to 4K/8K, H.264/VP9/AV1). Uses a distributed job system running on custom video transcoding hardware (VCUs). Applies perceptual quality optimization to minimize bitrate while maintaining visual quality.
</ComponentCard>
<ComponentCard name="Playback Service">
Serves video segments via adaptive bitrate streaming (DASH). Selects the optimal CDN PoP and format based on client capabilities, network conditions, and geographic location. Handles DRM for premium content.
</ComponentCard>
<ComponentCard name="Recommendation Engine">
Drives 70%+ of watch time. Uses a deep learning model (two-tower architecture: candidate generation + ranking) trained on user watch history, engagement signals, and content features. Serves personalized recommendations in &lt;200ms.
</ComponentCard>
<ComponentCard name="Ad Serving">
Real-time auction system that selects and inserts ads into video playback. Considers advertiser targeting, user demographics, content suitability, and bid price. Supports pre-roll, mid-roll, and overlay ad formats.
</ComponentCard>
<ComponentCard name="Content Moderation & Content ID">
ML-based system that scans uploads for policy violations (violence, spam, misinformation) and copyright infringement. Content ID fingerprints audio/video against a database of 100M+ reference files from rights holders.
</ComponentCard>
<ComponentCard name="Live Streaming Service">
Ingests RTMP streams from creators, transcodes in real-time at multiple qualities, and distributes via CDN with 2-15 second latency. Handles real-time chat, Super Chat payments, and live DVR (rewind).
</ComponentCard>
</ComponentList>

## Data Model

<Mermaid chart={`erDiagram
    VIDEO {
        string video_id PK
        string channel_id FK
        string title
        string description
        enum status
        int duration_seconds
        bigint view_count
        bigint like_count
        timestamp published_at
    }
    CHANNEL {
        string channel_id PK
        string user_id FK
        string name
        bigint subscriber_count
        timestamp created_at
    }
    VIDEO_FORMAT {
        string format_id PK
        string video_id FK
        enum codec
        int width
        int height
        int bitrate_kbps
        string blob_path
    }
    WATCH_EVENT {
        string event_id PK
        string user_id FK
        string video_id FK
        int watch_duration_sec
        float completion_rate
        timestamp watched_at
    }
    COMMENT {
        string comment_id PK
        string video_id FK
        string author_id FK
        string text
        bigint like_count
        timestamp created_at
    }
    CHANNEL ||--o{ VIDEO : uploads
    VIDEO ||--o{ VIDEO_FORMAT : has
    VIDEO ||--o{ WATCH_EVENT : generates
    VIDEO ||--o{ COMMENT : has`} caption="YouTube — Entity relationship diagram" />

## Video Transcoding at Scale

YouTube transcodes 500+ hours of video every minute into dozens of format combinations. This is one of the largest transcoding workloads on Earth.

**Format matrix**: Each video is encoded into multiple resolutions (144p, 240p, 360p, 480p, 720p, 1080p, 1440p, 4K, 8K) × multiple codecs (H.264 for compatibility, VP9 for quality/size, AV1 for next-gen efficiency). That's 20-30+ variants per video.

**Custom hardware**: YouTube uses custom **Video Coding Units (VCUs)** — ASICs designed specifically for video transcoding. These are 20-30x more power-efficient than general-purpose CPUs for this workload.

**Perceptual quality optimization**: YouTube doesn't use fixed bitrate targets. Instead, it uses a perceptual quality metric (SSIM/VMAF) to find the minimum bitrate that achieves a target quality level. Simple scenes (talking head) get lower bitrate; complex scenes (action, sports) get higher bitrate. This saves 20-50% bandwidth with no visible quality loss.

**Prioritized encoding**: Popular videos are re-encoded with more compute-intensive settings (slower presets, more passes) because the bandwidth savings multiply across millions of views. Rarely watched videos use faster, less optimal encoding.

<Mermaid chart={`graph LR
    UPLOAD[Raw Upload] --> SPLIT[Chunk Splitter]
    SPLIT --> E1[Encode 1080p H.264]
    SPLIT --> E2[Encode 1080p VP9]
    SPLIT --> E3[Encode 720p H.264]
    SPLIT --> E4[Encode 720p VP9]
    SPLIT --> E5[Encode 4K AV1]
    SPLIT --> EN[... 20+ formats]
    E1 & E2 & E3 & E4 & E5 & EN --> STORE[Blob Store]
    STORE --> CDN[CDN Distribution]`} caption="Video Transcoding at Scale" />

## Recommendation System Architecture

YouTube's recommendation engine drives over 70% of total watch time. It's a massive-scale ML system serving billions of recommendations per day.

**Two-stage architecture**:
1. **Candidate generation**: From a corpus of 800M+ videos, a lightweight model narrows down to ~1,000 candidates relevant to the user. Uses a deep neural network that embeds user history and video features into the same vector space, then performs approximate nearest-neighbor search.
2. **Ranking**: A more powerful model scores each candidate on predicted watch time, engagement probability, and satisfaction metrics. This model considers hundreds of features: video freshness, channel relationship, time of day, device type, etc.

**Training**: Models are trained on petabytes of user interaction data. The primary objective is **expected watch time** (not click-through rate) to avoid clickbait optimization. Additional objectives include user satisfaction signals (likes, surveys) and diversity.

**Serving**: The recommendation pipeline runs in &lt;200ms. Candidate generation uses an ANN (Approximate Nearest Neighbor) index served from memory. Ranking runs on TPUs for inference.

**Exploration**: A fraction of recommendations are intentionally exploratory — surfacing content from new creators or outside the user's typical interests — to prevent filter bubbles and help new creators get discovered.

## Content ID and Copyright Detection

YouTube's **Content ID** system is one of the largest audio/video fingerprinting systems in the world, protecting the intellectual property of rights holders.

**Reference database**: Rights holders upload reference files (songs, movies, TV shows) to Content ID. The system generates a compact digital fingerprint of each reference — a representation of the audio and video characteristics.

**Fingerprint matching**: Every uploaded video is fingerprinted and compared against the 100M+ reference files. The matching algorithm is robust to modifications — it can detect copyrighted content even when the audio pitch is shifted, the video is cropped, or the content is overlaid with other elements.

**Policy enforcement**: When a match is found, the rights holder's policy is applied automatically:
- **Block**: Video is taken down
- **Monetize**: Ads are placed on the video and revenue goes to the rights holder
- **Track**: The match is recorded but no action is taken

**Scale**: Content ID scans 500+ hours of video per minute against 100M+ reference files. The fingerprint comparison uses locality-sensitive hashing (LSH) for sub-linear search time.

**Appeals**: Creators can dispute Content ID claims, triggering a manual review process. The system handles millions of claims and disputes per month.

## Architectural Tradeoffs

<Tradeoff
  decision="Multiple codec support (H.264 + VP9 + AV1)"
  pros={['Broad device compatibility', 'Progressive quality improvement as clients adopt newer codecs', 'AV1 provides 30-50% bitrate savings over VP9']}
  cons={['Transcoding cost multiplied per codec', 'Massive storage for all format variants', 'Complex playback client logic for format selection']}
/>

<Tradeoff
  decision="Watch time optimization over click-through rate"
  pros={['Reduces clickbait and low-quality content', 'Better aligns with user satisfaction', 'Longer sessions increase ad revenue naturally']}
  cons={['Can create "rabbit hole" effect with increasingly engaging content', 'Harder to optimize than simple CTR', 'New creators with short content may be disadvantaged']}
/>

<Tradeoff
  decision="Custom transcoding hardware (VCUs) over general-purpose compute"
  pros={["20-30x better power efficiency", "Purpose-built for YouTube's workload", 'Lower operational cost at scale']}
  cons={['High upfront hardware development cost', 'Less flexible than CPUs/GPUs', 'Multi-year commitment to a hardware design']}
/>
